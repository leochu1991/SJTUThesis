1588协议的不足及解决
一. 往返的传输延时不一定对称。
在同步过程中，我们有两次重要的计算：Delay计算和Offset计算。前者用来计算传输延时，此时我们假设往返对称，则意味着两次传输的延时相等。基于这个假设，才能得到offset。但是，在实际传输中，由于网络负载情况不同，ptp报文在路径中的各边界时钟处停留时间不固定，此处包括排队延时和堵塞延时。而且，即使网络情况一直良好，该延时本身也具有一定的抖动和漂移，不可能在往返两次中保持相等。

分析：
首先，明确会影响延时的因素：
1. 中间时钟的排队延时和堵塞延时占主要。排队延时即等待队列前面所有报文全部发送所需要的时间；堵塞延时是已经轮到自己发送，但机器需要进行的发送处理时间。这些时间占延时变化的主要因素；
2. 延时自身的抖动和漂移。
另外，延时的计算：
一般而言，一次Delay_Req报文的发送会对应多个Sync报文。即假设之前已有一个delay值，然后发送了10个sync报文来同步，正常来讲，会默认这10个sync报文的延时都是之前的delay并用来进行计算offset。然后会发送一次Delay_Req报文，这个报文及之后的Delay_Resp可以用来计算新的delay值用到之后用。
其实这里面已经有不少问题，从延时‘瞬时性’突变和路径变化带来的延时‘持久性’变化

首先为了得到每次sync过程的最真实的delay，最后应该在每个sync报文之后立即发送Delay_Req报文来计算当前的delay。不过，上面的做法也有一定好处：减少网络负载，而且sync报文间隔一般比较短，所以默认这10个sync都共用一个delay。
应对延时‘瞬时性’突变的策略当然是要忽略这些‘突变点’，或者通过‘线性回归’或‘均值处理’等其他滤波方法减小这些‘突变点’带来的影响。

另一个问题是每次用来计算的delay一般都是上一次计算过的delay，万一sync过程中出现延时变化，如传输拓扑结构变化，意味着真实的延时已经完全不同了，即带来了‘持久性’变化。
应对延时‘持久性’变化的策略是：从历史延时数据来看，会发现delay突然变化到另外一条水平线，而且之后的delay也都在新的水平线附近。此时我们保持观测多个新数据点，若断定是‘持久性’而非‘瞬时性’，则应该抛弃历史数据而采用新的数据来计算offset。

后果：
由于offset的计算直接取决于延时的精确程度，如果延时计算有误，那么给offset带来的误差会直接破坏时钟的同步性能，精度降低，甚至有可能导致同步失去稳定。

解决：
所以，为了得到一个精确的延时，我们可以采用延时估计(预测)，
即依靠延时历史数据，来估计当前真实的延时，一方面减小延时的抖动漂移，另一方面可以处理‘瞬时性’和‘持久性’延时变化。
具体的估计方法有如下几种：
1. 可以利用线性核/RBF核方法对时延序列样本进行回归建模，得到一条直线，这种方法有很好的函数逼近能力和更高的精度，可以充分减小延时抖动漂移。
2. 采用简单点的最小均方差线性回归或者均值估算法，直接计算出当前延时估计值，也能较好处理延时。

这两种方法能有效减小延时抖动漂移和瞬时性突变，但是，对于‘持久性’延时变化并不具备良好的处理能力。
所以，我们需要在估计当前延时的同时，也要检测延时的变化情况。
假设没有发生‘持久性’延时，那么依靠历史数据能得到一条接近水平的回归线，而如果发生了‘持久性’延时，那么这条直线的斜率会随着时间积累不断增大，所以，我们可以监测最近的若干个延时，假设取近20个延时作为检测延时的滑动固定时间监测窗，同时从回归模型中取出这20个延时之前的一次延时估值，作为历史延时基准值，
那么我们可以计算这些检测延时与该历史基准值之间最小二次方差作为波动值，同时设置一个波动阈值，若该波动值超过阈值，那么认为发生‘持久性’延时，基于这20个延时建立新的回归模型，并重新开始估计之后的延时。

小结：
上述已经分析并从数据统计的角度处理了延时抖动漂移、‘瞬时性’延时和‘持久性’延时变化。

二、如何来校正从时钟的相位和频率
经过上述步骤，我们可以得到较好的delay值，经过sync报文后便可以得到较为优良的offset值，那么如何来校正呢？
1. 直接校正
相位：
通过计算的offset值直接校正本地时钟相位，优点是响应快，超调时间短。缺点是不能保证从时钟的稳定性，一旦计算出来的offset出现较大偏差，那么会严重破坏从时钟的时钟质量，而且，有很可能会造成从时钟不稳定，出现大幅波动。
频率校正：？？
2. 通过先进控制方法
这里采用三层增强BP神经网络，输入为延时和offset值，通过不断学习计算出pid控制器所需的三个参数，把这三个参数应用于PID控制器，用来对本地时钟进行校正。








